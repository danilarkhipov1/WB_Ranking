{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6457ccd4-4523-4c76-b58d-07d860b73f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d8e102-a4e6-41ef-8de0-b0a2025c2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_parquet(\"C:\\\\Users\\\\User\\\\Downloads\\\\train_features.parquet\")\n",
    "df_test = pl.read_parquet(\"C:\\\\Users\\\\User\\\\Downloads\\\\test_features.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a3e980-7bef-431d-b6be-0dede880a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [f\"feature_{i}\" for i in range(1, 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe50df-8a0c-4366-be07-1626891d5b88",
   "metadata": {},
   "source": [
    "## Заполнитель пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b748d504-686c-4b4d-ae06-55b603a52d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPLImputer:\n",
    "    def __init__(self):\n",
    "        self.feature_means = {}\n",
    "        \n",
    "    def fit(self, x: pl.DataFrame): \n",
    "        self.feature_means = x.mean().to_dicts()[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x: pl.DataFrame) -> pl.DataFrame:\n",
    "        return (\n",
    "            x\n",
    "            .with_columns(*[\n",
    "                pl.col(col).fill_null(val)\n",
    "                for col, val in self.feature_means.items()\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    \n",
    "imputer = MeanPLImputer().fit(df_train.select(*feature_columns))\n",
    "\n",
    "\n",
    "df_test = imputer.transform(df_test)\n",
    "df_train = imputer.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195e2c3-170d-496d-99ee-053c7912ef69",
   "metadata": {},
   "source": [
    "## Разделим на трейн и вал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731703b6-70dd-4e4b-88cd-a08fd74ff6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pd = df_train.to_pandas()\n",
    "df_test_pd = df_test.to_pandas()\n",
    "\n",
    "train_query_ids, val_query_ids = train_test_split(\n",
    "    np.arange(df_train.shape[0]),\n",
    "    random_state=42, \n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "# Отбор тренировочных и валидационных данных\n",
    "train_df = df_train_pd[df_train_pd[\"query_id\"].isin(train_query_ids)]\n",
    "val_df = df_train_pd[df_train_pd[\"query_id\"].isin(val_query_ids)]\n",
    "# Преобразование DataFrame из Pandas в Polars\n",
    "train_df = pl.from_pandas(train_df)\n",
    "val_df = pl.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d58f400-1be7-42bc-8f52-157a9dec37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pd=train_df.to_pandas()\n",
    "val_df_pd=val_df.to_pandas()\n",
    "train_df_pd['target'] = train_df_pd['target'].astype(int)\n",
    "val_df_pd['target'] = val_df_pd['target'].astype(int)\n",
    "df_test_pd['target'] = df_test_pd['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd18678-5386-4588-ac86-14b88d84baab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b9455cc-633a-4661-b5a9-ad0450d1aa25",
   "metadata": {},
   "source": [
    "# LambdaMart модель в реализации от LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2d5c6-02df-463e-af56-494a8a04d224",
   "metadata": {},
   "source": [
    "### Подготовим данные для обучения модели Lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1387f394-bc27-4b4f-97dd-3afdc8dd394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids_train = train_df_pd.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "X_train = train_df_pd.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1)\n",
    "y_train = train_df_pd[\"target\"]\n",
    "qids_validation = val_df_pd.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "X_validation = val_df_pd.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1)\n",
    "y_validation = val_df_pd[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158bc7c1-becc-45ca-84e8-ccc56000a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[int(i) for i in range(int(max(y_train.max(), y_validation.max())) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e1422-d10f-4d88-872d-4f92cc3a67b8",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe9d4a5-815d-4978-9a4b-af2e76b738fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n",
      "Training time: 83.54031729698181 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.96051147, -0.36472838,  0.12885933, ..., -1.48282238,\n",
       "       -0.92608394, -0.1198773 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\", label_gain=a\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    group=qids_train,\n",
    "    eval_set=[(X_validation, y_validation)],\n",
    "    eval_group=[qids_validation]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac016b7-aedd-4d6f-980b-64299ee9e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04aa63e1-991d-4bf4-b51d-4850472a1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_pd['rank'] = (val_df_pd.assign(pred=y_pred).groupby('query_id')['pred']\n",
    "                            .rank(method='dense', ascending=False).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc8cfe7e-24c7-43a8-b8b6-c302a12cd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Эта функция считает Hitrate\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "\n",
    "def ap_at_k(relevances, k=10):\n",
    "    total_relevant = sum(relevances[:k])\n",
    "    \n",
    "    if total_relevant == 0:\n",
    "        return 0\n",
    "    \n",
    "    ap_ = 0\n",
    "    for k_ in range(1, k+1):\n",
    "        ap_ += sum(relevances[:k_]) * relevances[k_ - 1] / k_\n",
    "        \n",
    "    return ap_ / total_relevant\n",
    "\n",
    "def calc_metrics(df, rn_col):\n",
    "    return (\n",
    "        df\n",
    "        .sort_values(rn_col)\n",
    "        .groupby(\"query_id\")\n",
    "        .agg(\n",
    "            hit_at_1=(\"target\", lambda x: x[:1].sum() > 0),\n",
    "            hit_at_5=(\"target\", lambda x: x[:5].sum() > 0),\n",
    "            hit_at_10=(\"target\", lambda x: x[:10].sum() > 0)\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1d9b0-877f-4759-b007-b246fd1a5c75",
   "metadata": {},
   "source": [
    "## Вычисляем средние метрики получившейся модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc401711-b5df-4853-85a8-46118dc93ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit_at_1     0.149047\n",
      "hit_at_5     0.400858\n",
      "hit_at_10    0.551560\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "metrics = calc_metrics(val_df_pd[['query_id', 'rank', 'target']], 'rank')\n",
    "mean_metrics = metrics.mean()\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b64da-d242-415e-a7ed-d3ebee865b2e",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4fec42-4869-4b77-bfc4-a6bdfcde32ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:25:28,397] A new study created in memory with name: no-name-69f3f38f-9138-4e0a-9fdd-8a6a9fe494bb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:28:18,635] Trial 0 finished with value: 0.14946117244362528 and parameters: {'learning_rate': 0.06875170926881327, 'n_estimators': 236, 'max_depth': 4, 'min_child_samples': 18, 'subsample': 0.8630416602886275, 'colsample_bytree': 0.9755814739522546, 'reg_alpha': 0.45545064469608687, 'reg_lambda': 0.6994553032621015}. Best is trial 0 with value: 0.14946117244362528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.208139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:30:10,150] Trial 1 finished with value: 0.14885934061800607 and parameters: {'learning_rate': 0.08131652825331241, 'n_estimators': 127, 'max_depth': 6, 'min_child_samples': 14, 'subsample': 0.8774124567490154, 'colsample_bytree': 0.9970996043346079, 'reg_alpha': 0.7155440496045693, 'reg_lambda': 0.11224494248446559}. Best is trial 0 with value: 0.14946117244362528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.197221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:33:55,491] Trial 2 finished with value: 0.1523386808598672 and parameters: {'learning_rate': 0.07869101549616986, 'n_estimators': 291, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.941158485417517, 'colsample_bytree': 0.907007175934875, 'reg_alpha': 0.7032758879741805, 'reg_lambda': 0.9472434341970295}. Best is trial 2 with value: 0.1523386808598672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:36:21,395] Trial 3 finished with value: 0.14417633672490643 and parameters: {'learning_rate': 0.022145564070304075, 'n_estimators': 203, 'max_depth': 4, 'min_child_samples': 25, 'subsample': 0.7185560705175433, 'colsample_bytree': 0.7120844785242483, 'reg_alpha': 0.6956489364970787, 'reg_lambda': 0.9996230289137155}. Best is trial 2 with value: 0.1523386808598672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 18147234, number of used features: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 22:38:09,608] Trial 4 finished with value: 0.14411991499125462 and parameters: {'learning_rate': 0.020452950017027665, 'n_estimators': 140, 'max_depth': 4, 'min_child_samples': 12, 'subsample': 0.9958644905849818, 'colsample_bytree': 0.7333147264330144, 'reg_alpha': 0.9974141619195724, 'reg_lambda': 0.217466201544519}. Best is trial 2 with value: 0.1523386808598672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.07869101549616986, 'n_estimators': 291, 'max_depth': 7, 'min_child_samples': 28, 'subsample': 0.941158485417517, 'colsample_bytree': 0.907007175934875, 'reg_alpha': 0.7032758879741805, 'reg_lambda': 0.9472434341970295}\n",
      "Best score found (hitrate@1):\n",
      "0.1523386808598672\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Определение функции для оптимизации гиперпараметров\n",
    "def objective(trial):\n",
    "    # Определение пространства поиска гиперпараметров\n",
    "    param = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 30),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "    }\n",
    "    \n",
    "    # Создание модели LightGBM\n",
    "    model = lgb.LGBMRanker(**param)\n",
    "    \n",
    "    # Обучение модели\n",
    "    model.fit(X_train, y_train, group=qids_train)\n",
    "    \n",
    "    # Предсказание на валидационном наборе\n",
    "    y_pred = model.predict(X_validation)\n",
    "    \n",
    "    # Ранжирование предсказаний\n",
    "    val_df_pd['rank'] = (val_df_pd.assign(pred=y_pred)\n",
    "                             .groupby('query_id')['pred']\n",
    "                             .rank(method='dense', ascending=False)\n",
    "                             .astype(int))\n",
    "    \n",
    "    # Вычисление метрики качества hitrate@1\n",
    "    metrics = calc_metrics(val_df_pd[['query_id', 'rank', 'target']], 'rank')\n",
    "    hitrate_at_1 = metrics['hit_at_1'].mean()\n",
    "    \n",
    "    # Возвращаем метрику hitrate@1 для оптимизации\n",
    "    return hitrate_at_1\n",
    "\n",
    "\n",
    "# Создание экземпляра Study для оптимизации\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Вывод наилучших гиперпараметров и оценки\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)\n",
    "print(\"Best score found (hitrate@1):\")\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83f1cd-f56b-47a6-925b-68364f8e90f7",
   "metadata": {},
   "source": [
    "## Вычислим метрики после кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c0955ab-8b6c-4341-887e-c0a94a564dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1803\n",
      "[LightGBM] [Info] Number of data points in the train set: 14517791, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22600\\3804332900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 14517791, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22600\\3804332900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1810\n",
      "[LightGBM] [Info] Number of data points in the train set: 14517791, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22600\\3804332900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1812\n",
      "[LightGBM] [Info] Number of data points in the train set: 14517791, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22600\\3804332900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.137437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1814\n",
      "[LightGBM] [Info] Number of data points in the train set: 14517772, number of used features: 11\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22600\\3804332900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hit_at_1  hit_at_5  hit_at_10\n",
      "mean  0.151902  0.407933   0.558840\n",
      "std   0.002553  0.003089   0.002375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics_cv(df, n_splits=5, **model_params):\n",
    "    skf = GroupKFold(n_splits=n_splits)\n",
    "    metrics = []\n",
    "\n",
    "    for train_index, val_index in skf.split(df.drop(['target'],axis=1), y=df['target'], groups=df[\"query_id\"]):\n",
    "        train_data = df.iloc[train_index]\n",
    "        val_data = df.iloc[val_index]\n",
    "\n",
    "        qids_train = train_data.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "        X_train = train_data.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1)\n",
    "        y_train = train_data[\"target\"]\n",
    "\n",
    "        qids_validation = val_data.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "        X_validation = val_data.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1)\n",
    "        y_validation = val_data[\"target\"]\n",
    "\n",
    "        model = lgb.LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\", **model_params)\n",
    "        model.fit(X=X_train, y=y_train, group=qids_train, eval_set=[(X_validation, y_validation)], eval_group=[qids_validation])\n",
    "\n",
    "        y_pred = model.predict(X_validation)\n",
    "        val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
    "\n",
    "        fold_metrics = calc_metrics(val_data[['query_id', 'rank', 'target']], 'rank')\n",
    "        metrics.append(fold_metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Пример использования:\n",
    "cv_metrics = get_metrics_cv(train_df_pd, **study.best_params)\n",
    "cv_mean_metrics = pd.DataFrame.from_records(map(lambda x: x.mean(), cv_metrics))\n",
    "print(cv_mean_metrics.agg([\"mean\", \"std\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be585d-d2a4-498e-b15c-b3cbd79abf33",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87a7a3-72cd-4a45-8f96-320fbd98c347",
   "metadata": {},
   "source": [
    "## Получаем среднее значение метрики Hit@1 после подбора гиперпараметров и кросс-валидации 0.151902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99379e-a21b-42af-87ec-905f8bce0042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafe88a-5140-494b-afe2-52f9268c356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a50de19f-bdd0-4526-9aa8-712cc8bb1e6f",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f4e2d-80ac-4328-ae72-bf3133f6dd21",
   "metadata": {},
   "source": [
    "### Будем использовать YetiRank для предсказания рангов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe3181c-236c-4c36-ac73-6a7244db1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1af0b13-4d84-4396-8aa8-21361c162007",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool=cb.Pool(train_df_pd.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1),label=train_df_pd[\"target\"],group_id=train_df_pd[\"query_id\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d00a83d-e050-4d05-8754-ac7c8466bd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 5.68s\tremaining: 1m 47s\n",
      "2:\ttotal: 16.5s\tremaining: 1m 33s\n",
      "4:\ttotal: 27.4s\tremaining: 1m 22s\n",
      "6:\ttotal: 38.2s\tremaining: 1m 10s\n",
      "8:\ttotal: 48.9s\tremaining: 59.8s\n",
      "10:\ttotal: 59.7s\tremaining: 48.8s\n",
      "12:\ttotal: 1m 10s\tremaining: 38s\n",
      "14:\ttotal: 1m 21s\tremaining: 27.2s\n",
      "16:\ttotal: 1m 32s\tremaining: 16.3s\n",
      "18:\ttotal: 1m 43s\tremaining: 5.43s\n",
      "19:\ttotal: 1m 48s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x1be5763d350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict={\n",
    "    \"loss_function\":\"YetiRank\",\n",
    "    \"iterations\":20,\n",
    "    \"verbose\":2,\n",
    "    \"max_ctr_complexity\":1\n",
    "}\n",
    "model=cb.CatBoostRanker(**params_dict)\n",
    "model.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e742cd46-3c3c-413f-93d2-3c69dcec5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(df_test_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da71d198-7d0a-429d-9c95-179c89f77dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pd['rank'] = (df_test_pd.assign(pred=y_pred).groupby('query_id')['pred']\n",
    "                            .rank(method='dense', ascending=False).astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361b3a1-8832-44b5-8a94-b683e69f4c9c",
   "metadata": {},
   "source": [
    "### Вычислим средние метрики обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d9870b-430b-4700-a96b-261f35e9ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit_at_1     0.149024\n",
      "hit_at_5     0.387452\n",
      "hit_at_10    0.530380\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "metrics = calc_metrics(df_test_pd[['query_id', 'rank', 'target']], 'rank')\n",
    "mean_metrics = metrics.mean()\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d0989-28dc-43bf-bfaf-ca7599885a3a",
   "metadata": {},
   "source": [
    "## Подберём гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb7c4d7-fd23-4c40-9e03-4fb987a36211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-08 00:41:34,382] A new study created in memory with name: no-name-aee2900f-5097-41d7-9061-6864389320e0\n",
      "[I 2024-05-08 00:44:18,814] Trial 0 finished with value: 0.14440202365951366 and parameters: {'learning_rate': 0.04600910179950901, 'depth': 7}. Best is trial 0 with value: 0.14440202365951366.\n",
      "[I 2024-05-08 00:47:03,044] Trial 1 finished with value: 0.1455492655771003 and parameters: {'learning_rate': 0.06452079358981212, 'depth': 7}. Best is trial 1 with value: 0.1455492655771003.\n",
      "[I 2024-05-08 00:49:45,277] Trial 2 finished with value: 0.14270937164995956 and parameters: {'learning_rate': 0.017352630638510287, 'depth': 7}. Best is trial 1 with value: 0.1455492655771003.\n",
      "[I 2024-05-08 00:52:29,135] Trial 3 finished with value: 0.14496624099603167 and parameters: {'learning_rate': 0.08208468813968268, 'depth': 6}. Best is trial 1 with value: 0.1455492655771003.\n",
      "[I 2024-05-08 00:55:09,815] Trial 4 finished with value: 0.14203231084613793 and parameters: {'learning_rate': 0.0279771995634691, 'depth': 6}. Best is trial 1 with value: 0.1455492655771003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.06452079358981212, 'depth': 7}\n",
      "Best score found (hitrate@1):\n",
      "0.1455492655771003\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Определение функции для оптимизации гиперпараметров\n",
    "def objective(trial):\n",
    "    # Определение пространства поиска гиперпараметров\n",
    "    param = {\n",
    "        \"loss_function\": 'YetiRank',\n",
    "        \"iterations\": 20,\n",
    "        \"verbose\": 0,\n",
    "        \"max_ctr_complexity\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 7),\n",
    "    }\n",
    "    \n",
    "    # Создание модели Catboost\n",
    "    model = cb.CatBoostRanker(**param)\n",
    "    \n",
    "    # Обучение модели\n",
    "    model.fit(train_pool, verbose_eval=False)\n",
    "    \n",
    "    # Предсказание на валидационном наборе\n",
    "    y_pred = model.predict(val_df_pd)\n",
    "    \n",
    "    # Ранжирование предсказаний\n",
    "    val_df_pd['rank'] = (val_df_pd.assign(pred=y_pred).groupby('query_id')['pred']\n",
    "                        .rank(method='dense', ascending=False).astype(int))\n",
    "    \n",
    "    # Вычисление метрики качества hitrate@1\n",
    "    metrics = calc_metrics(val_df_pd[['query_id', 'rank', 'target']], 'rank')\n",
    "    hitrate_at_1 = metrics['hit_at_1'].mean()\n",
    "    \n",
    "    # Возвращаем метрику hitrate@1 для оптимизации\n",
    "    return hitrate_at_1\n",
    "\n",
    "\n",
    "# Создание экземпляра Study для оптимизации\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Вывод наилучших гиперпараметров и оценки\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)\n",
    "print(\"Best score found (hitrate@1):\")\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5c01d-eaec-4df3-9f69-31567fae1623",
   "metadata": {},
   "source": [
    "### Вычислим финальные метрики на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7701736-802b-4235-8b79-c0bc4e30c7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26180\\2366607795.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26180\\2366607795.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26180\\2366607795.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26180\\2366607795.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26180\\2366607795.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hit_at_1  hit_at_5  hit_at_10\n",
      "mean  0.144099  0.382212   0.527405\n",
      "std   0.001213  0.002965   0.003054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics_cv(df, n_splits=5, **model_params):\n",
    "    skf = GroupKFold(n_splits=n_splits)\n",
    "    metrics = []\n",
    "\n",
    "    for train_index, val_index in skf.split(df.drop(['target'],axis=1), y=df['target'], groups=df[\"query_id\"]):\n",
    "        train_data = df.iloc[train_index]\n",
    "        val_data = df.iloc[val_index]\n",
    "\n",
    "        train_pool = cb.Pool(\n",
    "            data=train_data.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1),\n",
    "            label=train_data[\"target\"],\n",
    "            group_id=train_data[\"query_id\"]\n",
    "        )\n",
    "        \n",
    "        val_pool = cb.Pool(\n",
    "            data=val_data.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1),\n",
    "            label=val_data[\"target\"],\n",
    "            group_id=val_data[\"query_id\"]\n",
    "        )\n",
    "        model = cb.CatBoostRanker(**model_params)\n",
    "        model.fit(train_pool, eval_set=val_pool, verbose_eval=False)\n",
    "\n",
    "        y_pred = model.predict(val_pool)\n",
    "        val_data['rank'] = (val_data.assign(pred=y_pred).groupby('query_id')['pred'].rank(method='dense', ascending=False).astype(int))\n",
    "\n",
    "        fold_metrics = calc_metrics(val_data[['query_id', 'rank', 'target']], 'rank')\n",
    "        metrics.append(fold_metrics)\n",
    "\n",
    "    return metrics\n",
    "# Пример использования:\n",
    "cv_metrics = get_metrics_cv(train_df_pd, **params_dict)\n",
    "cv_mean_metrics = pd.DataFrame.from_records(map(lambda x: x.mean(), cv_metrics))\n",
    "print(cv_mean_metrics.agg([\"mean\", \"std\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443adb60-3706-4b94-ae65-cca18231d04e",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660662e-96f8-4f90-9287-3d268c7a7115",
   "metadata": {},
   "source": [
    "## Получаем среднее значение метрики Hit@1 после подбора гиперпараметров и кросс-валидации 0.144099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd9f77-8829-41ec-9b24-68ae53936f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552e8e1-de27-44c6-957c-1c71abf53331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1f519a-1e7d-4fd9-8ea5-32e9494faa0f",
   "metadata": {},
   "source": [
    "# RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751aea81-4dc7-46b8-a142-d4ecec29ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed09610b-d0d2-4d40-b9be-2dfe34e9f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids_train = train_df_pd.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "X_train = train_df_pd.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1).to_numpy()\n",
    "y_train = train_df_pd[\"target\"].to_numpy()\n",
    "qids_validation = val_df_pd.groupby(\"query_id\")[\"query_id\"].count().to_numpy()\n",
    "X_validation = val_df_pd.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1).to_numpy()\n",
    "y_validation = val_df_pd[\"target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb69d42b-3d0d-47ef-9446-7b263a2f725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=df_test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ffcd4e0-1b70-4953-86c8-90fc3991a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d5ee384-780e-4282-ba03-dc902d45063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNetTrainer:\n",
    "    def __init__(self, n_epochs=10, hidden_dim=22, lr=0.001):\n",
    "        self._prepare_data()\n",
    "        self.num_input_features = self.X_train.shape[1]\n",
    "        self.n_epochs = n_epochs\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.model = self._create_model(\n",
    "            self.num_input_features, hidden_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "    def _create_model(self, num_input_features:int, hidden_dim:int) -> torch.nn.Module:\n",
    "        torch.manual_seed(123)\n",
    "        net = RankNet(num_input_features=num_input_features, hidden_dim=hidden_dim)\n",
    "        return net\n",
    "    \n",
    "    def _get_data(self, train_df=train_df, test_df=test_df, feature_column=feature_columns) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        train_df, test_df = train_df, test_df\n",
    "        X_train, X_test = train_df[feature_column].to_numpy(), test_df[feature_column].to_numpy()\n",
    "        y_train, y_test = train_df[\"target\"].to_numpy(), test_df[\"target\"].to_numpy()\n",
    "        qids_train = train_df[\"query_id\"].to_numpy()\n",
    "        qids_test = test_df[\"query_id\"].to_numpy()\n",
    "        return X_train, y_train, qids_train, X_test, y_test, qids_test\n",
    "    \n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.qids_train, X_test, y_test, self.qids_test) = self._get_data()\n",
    "        X_train_copy = np.copy(X_train)\n",
    "        X_test_copy = np.copy(X_test)\n",
    "        X_train_copy = self._scale_features_in_query_groups(X_train_copy, self.qids_train)\n",
    "        X_test_copy = self._scale_features_in_query_groups(X_test_copy, self.qids_test)\n",
    "        self.X_train = torch.FloatTensor(X_train_copy)\n",
    "        self.X_test = torch.FloatTensor(X_test_copy)\n",
    "        self.ys_train = torch.FloatTensor(y_train)\n",
    "        self.ys_test = torch.FloatTensor(y_test)\n",
    "    \n",
    "        \n",
    "    def _scale_features_in_query_groups(self, inp_feat_array:np.ndarray, inp_query_ids:np.ndarray) -> np.ndarray:\n",
    "        scaler = StandardScaler()\n",
    "        for cur_id in np.unique(inp_query_ids):\n",
    "            mask = inp_query_ids == cur_id\n",
    "            tmp_array = inp_feat_array[mask]\n",
    "            inp_feat_array[mask] = scaler.fit_transform(tmp_array)\n",
    "        return inp_feat_array\n",
    "    \n",
    "    def fit(self):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        for epoch in range(1, self.n_epochs+1):\n",
    "            self.model.train()\n",
    "            for cur_id in np.unique(self.qids_train):\n",
    "                mask_train = self.qids_train == cur_id\n",
    "                batch_X = self.X_train[mask_train]\n",
    "                batch_ys = self.ys_train[mask_train]\n",
    "                self.optimizer.zero_grad()\n",
    "                logits = self.model(batch_X)\n",
    "                loss = criterion(logits.squeeze(), batch_ys)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "    def predict(self, X_test):\n",
    "        X_test_scaled = self._scale_features_in_query_groups(X_test, np.zeros(X_test.shape[0]))\n",
    "        tensor_X_test = torch.FloatTensor(X_test_scaled)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tensor_X_test)\n",
    "            probabilities = torch.sigmoid(logits.squeeze()).numpy()\n",
    "        return probabilities\n",
    "    def _eval_test_set(self, df_test):\n",
    "        X_test = df_test.drop([\"query_id\", \"report_date\", \"target\", \"rn\"], axis=1).to_numpy()\n",
    "        y_test = df_test[\"target\"].to_numpy()\n",
    "        predictions = self.predict(X_test)\n",
    "        df_test[\"predictions\"] = predictions\n",
    "        metrics = calc_metrics(df_test, \"predictions\")\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2ad8f-d00b-408a-9a0b-ebfa0c493665",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet = RankNetTrainer(n_epochs=2, hidden_dim=22, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bed2ed-4f2a-4041-9d80-5ba68823de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet.fit()\n",
    "ranknet_test = ranknet._eval_test_set(df_test_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94057c85-dcac-43ef-ac74-edb80e0426c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv)\n",
    "    metrics_list = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Обучение модели\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Получение предсказаний на валидационном наборе данных\n",
    "        predictions = model.predict(X_val)\n",
    "        \n",
    "        # Преобразование в DataFrame\n",
    "        df_val = pd.DataFrame({\"target\": y_val, \"predictions\": predictions})\n",
    "        \n",
    "        # Вычисление метрик\n",
    "        metrics = calc_metrics(df_val, \"predictions\")\n",
    "        \n",
    "        # Добавление метрик в список\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    return metrics_list\n",
    "\n",
    "# Создание экземпляра модели\n",
    "ranknet = RankNetTrainer(n_epochs=10, hidden_dim=22, lr=0.001)\n",
    "\n",
    "# Выполнение кросс-валидации\n",
    "cross_val_metrics = cross_validate(ranknet, X_train, y_train)\n",
    "\n",
    "# Вывод результатов\n",
    "for i, metrics in enumerate(cross_val_metrics, 1):\n",
    "    print(f\"Fold {i} metrics:\")\n",
    "    print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa93f79-0443-494c-a99c-972d988ee712",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "## В ходе решения были реализованы 3 модели (LambdaMART, YetiRank и RankNet)\n",
    "## Лучший результат по метрике hit@1 показала модель LambdaMART\n",
    "## Подбор гиперпараметров показал улучшение финальных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb286f39-02b1-4aac-a3f9-f50a7093207b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e4e0f-c060-47f9-b1da-15d04c11456f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c319f-ff81-4a44-b9c2-e2762e6d7156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f32b2d-6722-4978-9a3f-5e6330eae277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88c186-428d-4e5a-9295-770d4dca1cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4b6d3-c037-43a2-985c-bb016a64adfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f5f11-5e8a-4c6e-81a6-ccbc114bc998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e841b-2ede-48f2-9a0a-1937b35cc9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969eb8ac-e92b-488d-9623-e4ba521cf3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24af189-b640-4b2b-b7be-591293a3dbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437e45d-5e2b-47ae-92a3-6972c97ed009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a2614-2d6d-4ef1-aca3-2e7ee1285b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193c415-fc08-4991-bd33-03920fb5a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc7380-8f47-4e24-96d9-8976dcb6483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9f107-9c16-4a73-9615-1e1f1934079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e6059-f3f9-482c-9302-11604db0b222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cf874-43fd-44aa-864c-20ded29bcdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2c0bc-98d2-473e-bd00-42c2b851886c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36a946-e371-453c-bdd1-50d4dc15652d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5e0f6-f390-4144-8d89-0181d26b2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef346c8-0a4a-4f13-bf2b-2e79cf3f7695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60856c-d22b-479b-9b89-b9c6e24c1401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63590e15-c15f-40ed-8cac-31e7b45e8545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82e2b2-f99e-4d42-847f-b1ef778d4527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd89b2-aa7c-4dc5-9d5f-a9fa9495349c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821cda6-7f14-4afd-8686-cc9b5db1c24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9351e-b38f-4677-9ca2-221b37f849aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd17af2-6375-4647-84b8-971e1f8ca3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0ff0d-1bce-4622-a637-b35b50cdf09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d9925-4298-46f8-97a5-1ce4f6ab4fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde5564-e70e-4a34-9db9-80324b4c38a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590be55-13c6-4990-b1fd-40d6f3315dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473be405-686d-4237-a876-7de408659ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9b39d-629e-45df-b9da-c9b740249238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7889d6e-c818-4114-848e-d8af0515f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677a01c-e723-4c8c-9137-7ddfc8ac8017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4b4ec-de45-4d2f-9eb8-a0a952096bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73696286-c4cf-474f-9573-a95173c07f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b1e06-081b-4039-8301-66d78735fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14c16-b997-4f34-b9bb-55a079d628ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930edce4-de2d-4912-8a1a-fcf16912be7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bb93b-e174-40bb-a0a2-8b0c3b6c115b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f2c8a-1da1-4d95-bb61-6eef1c3fd169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcc260-f01c-4429-8ee1-8a4a9a70b956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dada64b-6fb8-4bd9-a7a6-fb6c8869a880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd520f1a-1a04-4ab4-a78c-d66b433c8d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ca66-8d4f-45de-906e-96e988bfb751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ae3a9-2429-401d-94bc-b2a30ee1b6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3a03d-eda6-465e-9dc5-fb242c1d1b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5a5e9-d6fd-4a3c-83b0-9616207461f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622a2df-6edb-40c3-a53e-4a8ba214d44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63df8f-de77-4c08-a6dd-e31df2b5f2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737e00c-4175-46c3-9dda-2e01dec427b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f00752-462f-494c-85b1-a97c8c99cef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
